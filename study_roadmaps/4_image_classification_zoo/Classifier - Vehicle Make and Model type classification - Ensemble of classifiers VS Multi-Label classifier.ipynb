{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/monk_v1/blob/master/study_roadmaps/4_image_classification_zoo/Classifier%20-%20Cifar10%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "\n",
    "## Install Monk\n",
    "\n",
    "\n",
    "## Using pretrained model for classifying elements in cifar-10 dataset\n",
    "\n",
    "\n",
    "## Training a classifier from scratch - Ensemble of clssifiers\n",
    "\n",
    "\n",
    "## Training a classifier from scratch - Single multi-label classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Monk\n",
    "\n",
    "  - git clone https://github.com/Tessellate-Imaging/monk_v1.git\n",
    "\n",
    "  - cd monk_v1/installation/Linux && pip install -r requirements_cu9.txt\n",
    "        (Select the requirements file as per OS and CUDA version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Tessellate-Imaging/monk_v1.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using Colab install using the commands below\n",
    "! cd monk_v1/installation/Misc && pip install -r requirements_colab.txt\n",
    "\n",
    "# If using Kaggle uncomment the following command\n",
    "#! cd monk_v1/installation/Misc && pip install -r requirements_kaggle.txt\n",
    "\n",
    "# Select the requirements file as per OS and CUDA version when using a local system or cloud\n",
    "#! cd monk_v1/installation/Linux && pip install -r requirements_cu9.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used trained classifier for demo - Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monk\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"monk_v1/monk/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Ojb_O7zJuzynRFyABJ75UHO0rrl-mC-N' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Ojb_O7zJuzynRFyABJ75UHO0rrl-mC-N\" -O cls_vehicle_trained.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq cls_vehicle_trained.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls workspace/Project-Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gluon project\n",
    "from gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf1 = prototype(verbose=0);\n",
    "gtf1.Prototype(\"Project-Vehicle\", \"Classify-Make-Type\", eval_infer=True);\n",
    "\n",
    "gtf2 = prototype(verbose=0);\n",
    "gtf2.Prototype(\"Project-Vehicle\", \"Classify-Model-Type\", eval_infer=True);\n",
    "\n",
    "gtf3 = prototype(verbose=0);\n",
    "gtf3.Prototype(\"Project-Vehicle\", \"Classify-Drive-Type\", eval_infer=True);\n",
    "\n",
    "gtf4 = prototype(verbose=0);\n",
    "gtf4.Prototype(\"Project-Vehicle\", \"Classify-Body-Style\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test1.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test2.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test3.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test4.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test5.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test6.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test6.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test7.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test8.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test9.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"workspace/test/test10.jpg\";\n",
    "print(\"Img name - \", img_name);\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "  \n",
    "  - Credits: https://github.com/nicolas-gervais/predicting-car-price-from-scraped-data/tree/master/picture-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1TQQuT60bddyeGBVfwNOk6nxYavxQdZJD' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1TQQuT60bddyeGBVfwNOk6nxYavxQdZJD\" -O thecarconnectionpicturedataset.rar && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get install unrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir thecarconnectionpicturedataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unrar x thecarconnectionpicturedataset.rar thecarconnectionpicturedataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a classifier from scratch - Ensemble of clssifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = os.listdir(\"thecarconnectionpicturedataset\");\n",
    "len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [];\n",
    "\n",
    "for i in tqdm(range(len(img_list))):\n",
    "    splits = img_list[i].split(\".\")[0].split(\"_\");\n",
    "    make = splits[0];\n",
    "       \n",
    "    make = make.replace(\" \", \"_\");\n",
    "    \n",
    "    \n",
    "    if make not in make_list:\n",
    "        make_list.append(make);\n",
    "    \n",
    "\n",
    "    combined.append([img_list[i], make])\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(combined, columns = ['ID', 'Labels'])\n",
    "df.to_csv(\"vehicles_make.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [];\n",
    "\n",
    "for i in tqdm(range(len(img_list))):\n",
    "    splits = img_list[i].split(\".\")[0].split(\"_\");\n",
    "    model = splits[1];\n",
    "       \n",
    "    model = model.replace(\" \", \"_\");\n",
    "    \n",
    "    \n",
    "    if model not in model_list:\n",
    "        model_list.append(model);\n",
    "    \n",
    "\n",
    "    combined.append([img_list[i], model])\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(combined, columns = ['ID', 'Labels'])\n",
    "df.to_csv(\"vehicles_model.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [];\n",
    "\n",
    "for i in tqdm(range(len(img_list))):\n",
    "    splits = img_list[i].split(\".\")[0].split(\"_\");\n",
    "    drive_type = splits[12];\n",
    "       \n",
    "    drive_type = drive_type.replace(\"FWD\", \"front_wheel_drive\");\n",
    "    drive_type = drive_type.replace(\"RWD\", \"rear_wheel_drive\");\n",
    "    drive_type = drive_type.replace(\"AWD\", \"all_wheel_drive\");\n",
    "    drive_type = drive_type.replace(\"4WD\", \"four_wheel_drive\");\n",
    "    \n",
    "    drive_type = drive_type.replace(\" \", \"_\");\n",
    "    \n",
    "    if drive_type not in drive_type_list:\n",
    "        drive_type_list.append(drive_type);\n",
    "    \n",
    "\n",
    "    combined.append([img_list[i], drive_type])\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(combined, columns = ['ID', 'Labels'])\n",
    "df.to_csv(\"vehicles_drive_type.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [];\n",
    "\n",
    "for i in tqdm(range(len(img_list))):\n",
    "    splits = img_list[i].split(\".\")[0].split(\"_\");\n",
    "    body_style = splits[15];\n",
    "       \n",
    "    body_style = body_style.replace(\"2dr\", \"2_door_car\");\n",
    "    body_style = body_style.replace(\"3dr\", \"3_door_car\");\n",
    "    body_style = body_style.replace(\"4dr\", \"4_door_car\");\n",
    "    \n",
    "    body_style = body_style.replace(\" \", \"_\");\n",
    "    \n",
    "    if body_style not in body_style_list:\n",
    "        body_style_list.append(body_style);\n",
    "\n",
    "    combined.append([img_list[i], body_style])\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(combined, columns = ['ID', 'Labels'])\n",
    "df.to_csv(\"vehicles_body_style.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monk\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"monk_v1/monk/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mxnet-gluon backend \n",
    "from gluon_prototype import prototype\n",
    "\n",
    "# For pytorch backend\n",
    "#from pytorch_prototype import prototype\n",
    "\n",
    "# For Keras backend\n",
    "#from keras_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Project and Experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Vehicle\", \"Classify-Make-Type\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Default(dataset_path=\"thecarconnectionpicturedataset/\", \n",
    "            path_to_csv=\"vehicles_make.csv\",\n",
    "            model_name=\"resnet50_v2\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.update_batch_size(128);\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monk\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"monk_v1/monk/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mxnet-gluon backend \n",
    "from gluon_prototype import prototype\n",
    "\n",
    "# For pytorch backend\n",
    "#from pytorch_prototype import prototype\n",
    "\n",
    "# For Keras backend\n",
    "#from keras_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Project and Experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Vehicle\", \"Classify-Model-Type\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Default(dataset_path=\"thecarconnectionpicturedataset/\", \n",
    "            path_to_csv=\"vehicles_model.csv\",\n",
    "            model_name=\"resnet50_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.update_batch_size(128);\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Drive type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monk\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"monk_v1/monk/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mxnet-gluon backend \n",
    "from gluon_prototype import prototype\n",
    "\n",
    "# For pytorch backend\n",
    "#from pytorch_prototype import prototype\n",
    "\n",
    "# For Keras backend\n",
    "#from keras_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Project and Experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Vehicle\", \"Classify-Drive-Type\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Default(dataset_path=\"thecarconnectionpicturedataset/\", \n",
    "            path_to_csv=\"vehicles_drive_type.csv\",\n",
    "            model_name=\"resnet50_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.update_batch_size(128);\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Body Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monk\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"monk_v1/monk/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mxnet-gluon backend \n",
    "from gluon_prototype import prototype\n",
    "\n",
    "# For pytorch backend\n",
    "#from pytorch_prototype import prototype\n",
    "\n",
    "# For Keras backend\n",
    "#from keras_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Project and Experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Vehicle\", \"Classify-Body-Style\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Default(dataset_path=\"thecarconnectionpicturedataset/\", \n",
    "            path_to_csv=\"vehicles_body_style.csv\",\n",
    "            model_name=\"resnet50_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.update_batch_size(128);\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monk\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"monk_v1/monk/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mxnet-gluon backend \n",
    "from gluon_prototype import prototype\n",
    "\n",
    "# For pytorch backend\n",
    "#from pytorch_prototype import prototype\n",
    "\n",
    "# For Keras backend\n",
    "#from keras_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf1 = prototype(verbose=0);\n",
    "gtf1.Prototype(\"Project-Vehicle\", \"Classify-Make-Type\", eval_infer=True);\n",
    "\n",
    "gtf2 = prototype(verbose=0);\n",
    "gtf2.Prototype(\"Project-Vehicle\", \"Classify-Model-Type\", eval_infer=True);\n",
    "\n",
    "gtf3 = prototype(verbose=0);\n",
    "gtf3.Prototype(\"Project-Vehicle\", \"Classify-Drive-Type\", eval_infer=True);\n",
    "\n",
    "gtf4 = prototype(verbose=0);\n",
    "gtf4.Prototype(\"Project-Vehicle\", \"Classify-Body-Style\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_list = os.listdir(\"thecarconnectionpicturedataset\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "img_name = \"thecarconnectionpicturedataset/\" + img_list[190];\n",
    "print(\"Img name - \", img_name);\n",
    "\n",
    "\n",
    "start = time.time();\n",
    "output1 = gtf1.Infer(img_name=img_name)\n",
    "output2 = gtf2.Infer(img_name=img_name)\n",
    "output3 = gtf3.Infer(img_name=img_name)\n",
    "output4 = gtf4.Infer(img_name=img_name)\n",
    "end = time.time();\n",
    "print(\"Time taken for predictions - \", end-start);\n",
    "\n",
    "print(\"Make Type- \", output1[\"predicted_class\"]);\n",
    "print(\"Model Type- \", output2[\"predicted_class\"]);\n",
    "print(\"Drive Type- \", output3[\"predicted_class\"]);\n",
    "print(\"Body Style - \", output4[\"predicted_class\"]);\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats at prediction time\n",
    "\n",
    "  - Memory taken on GPU - 1805 MB\n",
    "  - Avg prediction time - 0.05 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a classifier from scratch - Single multi-label classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-label CSV generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = os.listdir(\"thecarconnectionpicturedataset\");\n",
    "len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_list = [];\n",
    "model_list = [];\n",
    "drive_type_list = [];\n",
    "#passenger_capacity_list = [];\n",
    "#passenger_doors_list = [];\n",
    "body_style_list = [];\n",
    "\n",
    "combined = [];\n",
    "\n",
    "for i in tqdm(range(len(img_list))):\n",
    "    splits = img_list[i].split(\".\")[0].split(\"_\");\n",
    "    make = splits[0];\n",
    "    model = splits[1];\n",
    "    drive_type = splits[12];\n",
    "    #passenger_capacity = splits[13];\n",
    "    #passenger_doors = splits[14];\n",
    "    body_style = splits[15];\n",
    "    \n",
    "    drive_type = drive_type.replace(\"FWD\", \"front_wheel_drive\");\n",
    "    drive_type = drive_type.replace(\"RWD\", \"rear_wheel_drive\");\n",
    "    drive_type = drive_type.replace(\"AWD\", \"all_wheel_drive\");\n",
    "    drive_type = drive_type.replace(\"4WD\", \"four_wheel_drive\");\n",
    "    \n",
    "    \n",
    "    body_style = body_style.replace(\"2dr\", \"2_door_car\");\n",
    "    body_style = body_style.replace(\"3dr\", \"3_door_car\");\n",
    "    body_style = body_style.replace(\"4dr\", \"4_door_car\");\n",
    "    \n",
    "    make = make.replace(\" \", \"_\");\n",
    "    model = model.replace(\" \", \"_\");\n",
    "    drive_type = drive_type.replace(\" \", \"_\");\n",
    "    #passenger_capacity = passenger_capacity.replace(\" \", \"_\");\n",
    "    #passenger_doors = passenger_doors.replace(\" \", \"_\");\n",
    "    body_style = body_style.replace(\" \", \"_\");\n",
    "    \n",
    "    \n",
    "    \n",
    "    if make not in make_list:\n",
    "        make_list.append(make);\n",
    "    if model not in model_list:\n",
    "        model_list.append(model);\n",
    "    if drive_type not in drive_type_list:\n",
    "        drive_type_list.append(drive_type);\n",
    "    #if passenger_capacity not in passenger_capacity_list:\n",
    "    #    passenger_capacity_list.append(passenger_capacity);\n",
    "    #if passenger_doors not in passenger_doors_list:\n",
    "    #    passenger_doors_list.append(passenger_doors);\n",
    "    if body_style not in body_style_list:\n",
    "        body_style_list.append(body_style);\n",
    "    \n",
    "    wr_labels = make + \" \" + model + \" \" + drive_type + \" \" + body_style;\n",
    "    combined.append([img_list[i], wr_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(combined, columns = ['ID', 'Labels'])\n",
    "df.to_csv(\"vehicles.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"monk_v1/monk/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using mxnet-gluon backend \n",
    "from gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create project and experiment\n",
    "ptf = prototype(verbose=1);\n",
    "ptf.Prototype(\"Project-Vehicle\", \"Multi-Label-Classifier\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set data parameters\n",
    "\n",
    "ptf.Dataset_Params(dataset_path=\"./thecarconnectionpicturedataset\",\n",
    "                   path_to_csv=\"./vehicles.csv\",\n",
    "                   \n",
    "                   \n",
    "                   delimiter = \" \",\n",
    "                   \n",
    "                   \n",
    "                   split=0.9,\n",
    "                   input_size=224, \n",
    "                   batch_size=128, \n",
    "                   shuffle_data=True,\n",
    "                   num_processors=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply data transformations\n",
    "ptf.apply_random_horizontal_flip(train=True, val=True);\n",
    "ptf.apply_normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], train=True, val=True, test=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "ptf.Dataset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "ptf.Model_Params(model_name=\"resnet50_v1\", freeze_base_network=False, use_gpu=True, use_pretrained=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "ptf.Model();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Training parameters\n",
    "ptf.Training_Params(num_epochs=2, display_progress=True, display_progress_realtime=True, \n",
    "                    save_intermediate_models=False, save_training_logs=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "ptf.optimizer_rmsprop(0.001);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate scheduler\n",
    "ptf.lr_fixed();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function\n",
    "ptf.loss_sigmoid_binary_crossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Training\n",
    "ptf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"monk_v1/monk/\");\n",
    "\n",
    "from gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiment in evaluation and inferencing mode\n",
    "\n",
    "ptf = prototype(verbose=1);\n",
    "ptf.Prototype(\"Project-Vehicle\", \"Multi-Label-Classifier\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "img_name = \"thecarconnectionpicturedataset/\" + img_list[1490];\n",
    "\n",
    "start = time.time();\n",
    "output = ptf.Infer(img_name=img_name, return_raw=True)\n",
    "end = time.time();\n",
    "print(\"Time take to process - \", end-start)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats at prediction time\n",
    "\n",
    "  - Memory taken on GPU - 1181 MB\n",
    "  - Avg prediction time - 0.04 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
