{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
   "source": [
        "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/monk_v1/blob/master/study_roadmaps/4_image_classification_zoo/Blood%20Cell%20Type%20Classification:%20Understanding%20the%20impact%20of%20depth%20in%20network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    "\n",
    "\n",
    "### Train a blood cell type classifier using resnet variants\n",
    "\n",
    "### Understand what all differences happen when switching between resnets variants \n",
    "\n",
    "### Understand bigger and deeper network not always means better results\n",
    "\n",
    "#### For this experiment you will be using mxnet backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is resnet\n",
    "\n",
    "## Readings on resnet\n",
    "\n",
    "  1) Points from https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035\n",
    "    - The core idea of ResNet is introducing a so-called “identity shortcut connection” that skips one or more layers\n",
    "    - The deeper model should not produce a training error higher than its shallower counterparts.\n",
    "    - solves the problem of vanishing gradiens as network depth increased - https://medium.com/@anishsingh20/the-vanishing-gradient-problem-48ae7f501257\n",
    "    \n",
    "    \n",
    " \n",
    "  2) Points from https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624\n",
    "    - Won 1st place in the ILSVRC 2015 classification competition with top-5 error rate of 3.57% (An ensemble model)\n",
    "    - Efficiently trained networks with 100 layers and 1000 layers also.\n",
    "    - Replacing VGG-16 layers in Faster R-CNN with ResNet-101. They observed a relative improvements of 28%\n",
    "    \n",
    "\n",
    "  3) Read more here\n",
    "    - https://arxiv.org/abs/1512.03385\n",
    "    - https://d2l.ai/chapter_convolutional-modern/resnet.html\n",
    "    - https://cv-tricks.com/keras/understand-implement-resnets/\n",
    "    - https://mc.ai/resnet-architecture-explained/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "\n",
    "## [0. Install](#0)\n",
    "\n",
    "\n",
    "## [1. Train experiment with resnet-18 architecture and validate](#1)\n",
    "\n",
    "\n",
    "## [2. Train experiment with resnet-32 architecture and validate](#2)\n",
    "\n",
    "\n",
    "## [3. Train experiment with resnet-50 architecture and validate](#3)\n",
    "\n",
    "\n",
    "## [4. Train experiment with resnet-101 architecture and validate](#4)\n",
    "\n",
    "\n",
    "## [5. Train experiment with resnet-152 architecture and validate](#5)\n",
    "\n",
    "\n",
    "## [6. Compare all the 4 experiments](#11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# Install Monk\n",
    "  \n",
    " - git clone https://github.com/Tessellate-Imaging/monk_v1.git\n",
    " \n",
    " - cd monk_v1/installation/Linux && pip install -r requirements_cu9.txt\n",
    "     - (Select the requirements file as per OS and CUDA version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'monk_v1'...\n",
      "remote: Enumerating objects: 200, done.\u001b[K\n",
      "remote: Counting objects: 100% (200/200), done.\u001b[K\n",
      "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
      "remote: Total 2105 (delta 110), reused 116 (delta 53), pack-reused 1905\u001b[K\n",
      "Receiving objects: 100% (2105/2105), 73.71 MiB | 4.39 MiB/s, done.\n",
      "Resolving deltas: 100% (1130/1130), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Tessellate-Imaging/monk_v1.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the requirements file as per OS and CUDA version\n",
    "!cd monk_v1/installation/Linux && pip install -r requirements_cu9.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - Blood Cell Type Classification\n",
    "    - https://www.kaggle.com/paultimothymooney/blood-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1KhXKL58mnXL1G1uRDsCmCXMk7ubwXjps' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1KhXKL58mnXL1G1uRDsCmCXMk7ubwXjps\" -O blood-cells.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq blood-cells.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monk\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"monk_v1/monk/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using mxnet-gluon backend \n",
    "from gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# Train experiment with resnet-18 architecture and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.0\n",
      "\n",
      "Experiment Details\n",
      "    Project: Compare-resnet-v1-depth\n",
      "    Experiment: resnet18-v1\n",
      "    Dir: /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet18-v1/\n",
      "\n",
      "Dataset Details\n",
      "    Train path:     blood-cells/train\n",
      "    Val path:       None\n",
      "    CSV train path: None\n",
      "    CSV val path:   None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Data Shuffle: True\n",
      "    Processors:   4\n",
      "    Train-val split:   0.7\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 6969\n",
      "    Num val images:   2988\n",
      "    Num classes:      4\n",
      "\n",
      "Model Params\n",
      "    Model name:           resnet18_v1\n",
      "    Use Gpu:              True\n",
      "    Use pretrained:       True\n",
      "    Freeze base network:  False\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet18_v1\n",
      "        Num of potentially trainable layers:  41\n",
      "        Num of actual trainable layers:       41\n",
      "\n",
      "Optimizer\n",
      "    Name:          sgd\n",
      "    Learning rate: 0.01\n",
      "    Params:        {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Learning rate scheduler\n",
      "    Name:   steplr\n",
      "    Params: {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}\n",
      "\n",
      "Loss\n",
      "    Name:          softmaxcrossentropy\n",
      "    Params:        {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}\n",
      "\n",
      "Training params\n",
      "    Num Epochs: 5\n",
      "\n",
      "Display params\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save Training logs:        True\n",
      "    Save Intermediate models:  True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monk_v1/monk/system/imports.py:193: UserWarning: ArgumentWarning: clipnorm and clipvalue are active only for keras in current version of Monk\n",
      "  warnings.warn(msg)\n",
      "monk_v1/monk/system/imports.py:193: UserWarning: ArgumentWarning: momentum_dampening_rate is active only for pytorch in current version of Monk\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Compare-resnet-v1-depth\", \"resnet18-v1\");\n",
    "\n",
    "\n",
    "# Insert data and set params in default mode\n",
    "gtf.Default(dataset_path=\"blood-cells/train\", \n",
    "            model_name=\"resnet18_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=5);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "    Epoch 1/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec97bea3e5e434489915cd379737cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6156253d3bcb475ab7a3a79637173742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.01\n",
      "    [Epoch 1] Train-acc: 0.831, Train-loss: 0.478 | Val-acc: 0.939759, Val-loss: 0.193, | time: 49.3 sec\n",
      "\n",
      "    Epoch 2/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72616dc95d24dd9a29fa7082adfc1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad3fc7fafd7489cb7cfe0251f89e8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.0098\n",
      "    [Epoch 2] Train-acc: 0.952, Train-loss: 0.155 | Val-acc: 0.971553, Val-loss: 0.084, | time: 43.0 sec\n",
      "\n",
      "    Epoch 3/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e8df8781e7498581a2bd0b5c414b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff51cd99e8a4b88a2ee239cbdacbcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009604\n",
      "    [Epoch 3] Train-acc: 0.971, Train-loss: 0.102 | Val-acc: 0.982932, Val-loss: 0.065, | time: 43.4 sec\n",
      "\n",
      "    Epoch 4/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b78beb44024cda830fa684a89b5e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce525e4624c450d9f8ed6921f3fb5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009411919999999999\n",
      "    [Epoch 4] Train-acc: 0.982, Train-loss: 0.070 | Val-acc: 0.986948, Val-loss: 0.051, | time: 43.1 sec\n",
      "\n",
      "    Epoch 5/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e800b509a4bf4508a5b85640c6a2c448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26d8b9ed27149dd8d0b160b7d095756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009223681599999999\n",
      "    [Epoch 5] Train-acc: 0.989, Train-loss: 0.044 | Val-acc: 0.989960, Val-loss: 0.044, | time: 44.0 sec\n",
      "\n",
      "    Training completed in: 3m 42s\n",
      "    Best val Acc:          0.989960\n",
      "\n",
      "Training End\n",
      "\n",
      "Training Outputs\n",
      "    Model Dir:   /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet18-v1/output/models/\n",
      "    Log Dir:     /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet18-v1/output/logs/\n",
      "    Final model: final\n",
      "    Best model:  best_model\n",
      "    Log 1 - Validation accuracy history log: val_acc_history.npy\n",
      "    Log 2 - Validation loss history log:     val_loss_history.npy\n",
      "    Log 3 - Training accuracy history log:   train_acc_history.npy\n",
      "    Log 4 - Training loss history log:       train_loss_history.npy\n",
      "    Log 5 - Training curve:                  train_loss_history.npy\n",
      "    Log 6 - Validation curve:                train_loss_history.npy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start Training\n",
    "gtf.Train();\n",
    "\n",
    "#Read the training summary generated once you run the cell and training is completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.0\n",
      "\n",
      "Model Details\n",
      "    Loading model - workspace/Compare-resnet-v1-depth/resnet18-v1/output/models/final-symbol.json\n",
      "    Model loaded!\n",
      "\n",
      "Experiment Details\n",
      "    Project: Compare-resnet-v1-depth\n",
      "    Experiment: resnet18-v1\n",
      "    Dir: /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet18-v1/\n",
      "\n",
      "Dataset Details\n",
      "    Test path:      blood-cells/val\n",
      "    CSV test path:  None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:  224\n",
      "    Processors:   4\n",
      "\n",
      "Pre-Composed Test Transforms\n",
      "[{'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num test images: 2487\n",
      "    Num classes:      4\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9af337ad094750b6eb5a1cb769d53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2487), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Result\n",
      "        class based accuracies\n",
      "            0. EOSINOPHIL - 84.91171749598716 %\n",
      "            1. LYMPHOCYTE - 100.0 %\n",
      "            2. MONOCYTE - 75.0 %\n",
      "            3. NEUTROPHIL - 92.62820512820514 %\n",
      "        total images:            2487\n",
      "        num correct predictions: 2192\n",
      "        Average accuracy (%):    88.1383192601528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load for validation\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Compare-resnet-v1-depth\", \"resnet18-v1\", eval_infer=True);\n",
    "\n",
    "\n",
    "# Set dataset\n",
    "gtf.Dataset_Params(dataset_path=\"blood-cells/val\");\n",
    "gtf.Dataset();\n",
    "\n",
    "\n",
    "# Validate\n",
    "accuracy, class_based_accuracy = gtf.Evaluate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "# Train experiment with resnet-34 architecture and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.0\n",
      "\n",
      "Experiment Details\n",
      "    Project: Compare-resnet-v1-depth\n",
      "    Experiment: resnet34-v1\n",
      "    Dir: /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet34-v1/\n",
      "\n",
      "Dataset Details\n",
      "    Train path:     blood-cells/train\n",
      "    Val path:       None\n",
      "    CSV train path: None\n",
      "    CSV val path:   None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Data Shuffle: True\n",
      "    Processors:   4\n",
      "    Train-val split:   0.7\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 6969\n",
      "    Num val images:   2988\n",
      "    Num classes:      4\n",
      "\n",
      "Model Params\n",
      "    Model name:           resnet34_v1\n",
      "    Use Gpu:              True\n",
      "    Use pretrained:       True\n",
      "    Freeze base network:  False\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet34_v1\n",
      "        Num of potentially trainable layers:  73\n",
      "        Num of actual trainable layers:       73\n",
      "\n",
      "Optimizer\n",
      "    Name:          sgd\n",
      "    Learning rate: 0.01\n",
      "    Params:        {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Learning rate scheduler\n",
      "    Name:   steplr\n",
      "    Params: {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}\n",
      "\n",
      "Loss\n",
      "    Name:          softmaxcrossentropy\n",
      "    Params:        {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}\n",
      "\n",
      "Training params\n",
      "    Num Epochs: 5\n",
      "\n",
      "Display params\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save Training logs:        True\n",
      "    Save Intermediate models:  True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monk_v1/monk/system/imports.py:193: UserWarning: ArgumentWarning: clipnorm and clipvalue are active only for keras in current version of Monk\n",
      "  warnings.warn(msg)\n",
      "monk_v1/monk/system/imports.py:193: UserWarning: ArgumentWarning: momentum_dampening_rate is active only for pytorch in current version of Monk\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Compare-resnet-v1-depth\", \"resnet34-v1\");\n",
    "\n",
    "\n",
    "# Insert data and set params in default mode\n",
    "gtf.Default(dataset_path=\"blood-cells/train\", \n",
    "            model_name=\"resnet34_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "    Epoch 1/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b572351c04a641e5915f6fdcc092e6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbecaeadacd045e1a6f024397cfdf888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.01\n",
      "    [Epoch 1] Train-acc: 0.814, Train-loss: 0.539 | Val-acc: 0.935074, Val-loss: 0.204, | time: 66.7 sec\n",
      "\n",
      "    Epoch 2/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ef43e88b0a466e8cd9783bf8b7ff9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad09105b43734234bef2193f0a4e4987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.0098\n",
      "    [Epoch 2] Train-acc: 0.952, Train-loss: 0.153 | Val-acc: 0.973561, Val-loss: 0.103, | time: 65.3 sec\n",
      "\n",
      "    Epoch 3/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3930f6cb745c4a88946acd59dd4a064e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a070ca49ba2e496da61cf131711df36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009604\n",
      "    [Epoch 3] Train-acc: 0.974, Train-loss: 0.094 | Val-acc: 0.933735, Val-loss: 0.184, | time: 66.3 sec\n",
      "\n",
      "    Epoch 4/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed985d4c4af84aba85170fb4a6261fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd00059f4c04aed9d56ff9adcefda88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009411919999999999\n",
      "    [Epoch 4] Train-acc: 0.979, Train-loss: 0.075 | Val-acc: 0.964525, Val-loss: 0.113, | time: 67.1 sec\n",
      "\n",
      "    Epoch 5/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b109246d63f4044acbbf85663c75b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5447b8b47234f7781f712468acda5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009223681599999999\n",
      "    [Epoch 5] Train-acc: 0.990, Train-loss: 0.040 | Val-acc: 0.988621, Val-loss: 0.034, | time: 68.1 sec\n",
      "\n",
      "    Training completed in: 5m 32s\n",
      "    Best val Acc:          0.988621\n",
      "\n",
      "Training End\n",
      "\n",
      "Training Outputs\n",
      "    Model Dir:   /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet34-v1/output/models/\n",
      "    Log Dir:     /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet34-v1/output/logs/\n",
      "    Final model: final\n",
      "    Best model:  best_model\n",
      "    Log 1 - Validation accuracy history log: val_acc_history.npy\n",
      "    Log 2 - Validation loss history log:     val_loss_history.npy\n",
      "    Log 3 - Training accuracy history log:   train_acc_history.npy\n",
      "    Log 4 - Training loss history log:       train_loss_history.npy\n",
      "    Log 5 - Training curve:                  train_loss_history.npy\n",
      "    Log 6 - Validation curve:                train_loss_history.npy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start Training\n",
    "gtf.Train();\n",
    "\n",
    "#Read the training summary generated once you run the cell and training is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.0\n",
      "\n",
      "Model Details\n",
      "    Loading model - workspace/Compare-resnet-v1-depth/resnet34-v1/output/models/final-symbol.json\n",
      "    Model loaded!\n",
      "\n",
      "Experiment Details\n",
      "    Project: Compare-resnet-v1-depth\n",
      "    Experiment: resnet34-v1\n",
      "    Dir: /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet34-v1/\n",
      "\n",
      "Dataset Details\n",
      "    Test path:      blood-cells/val\n",
      "    CSV test path:  None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:  224\n",
      "    Processors:   4\n",
      "\n",
      "Pre-Composed Test Transforms\n",
      "[{'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num test images: 2487\n",
      "    Num classes:      4\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a99e4ca93fd40feb04e52b4e758e682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2487), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Result\n",
      "        class based accuracies\n",
      "            0. EOSINOPHIL - 86.19582664526484 %\n",
      "            1. LYMPHOCYTE - 100.0 %\n",
      "            2. MONOCYTE - 75.0 %\n",
      "            3. NEUTROPHIL - 88.78205128205127 %\n",
      "        total images:            2487\n",
      "        num correct predictions: 2176\n",
      "        Average accuracy (%):    87.49497386409328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load for validation\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Compare-resnet-v1-depth\", \"resnet34-v1\", eval_infer=True);\n",
    "\n",
    "\n",
    "# Set dataset\n",
    "gtf.Dataset_Params(dataset_path=\"blood-cells/val\");\n",
    "gtf.Dataset();\n",
    "\n",
    "\n",
    "# Validate\n",
    "accuracy, class_based_accuracy = gtf.Evaluate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# Train experiment with resnet-50 architecture and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.0\n",
      "\n",
      "Experiment Details\n",
      "    Project: Compare-resnet-v1-depth\n",
      "    Experiment: resnet50-v1\n",
      "    Dir: /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet50-v1/\n",
      "\n",
      "Dataset Details\n",
      "    Train path:     blood-cells/train\n",
      "    Val path:       None\n",
      "    CSV train path: None\n",
      "    CSV val path:   None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Data Shuffle: True\n",
      "    Processors:   4\n",
      "    Train-val split:   0.7\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 6969\n",
      "    Num val images:   2988\n",
      "    Num classes:      4\n",
      "\n",
      "Model Params\n",
      "    Model name:           resnet50_v1\n",
      "    Use Gpu:              True\n",
      "    Use pretrained:       True\n",
      "    Freeze base network:  False\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet50_v1\n",
      "        Num of potentially trainable layers:  107\n",
      "        Num of actual trainable layers:       107\n",
      "\n",
      "Optimizer\n",
      "    Name:          sgd\n",
      "    Learning rate: 0.01\n",
      "    Params:        {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Learning rate scheduler\n",
      "    Name:   steplr\n",
      "    Params: {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}\n",
      "\n",
      "Loss\n",
      "    Name:          softmaxcrossentropy\n",
      "    Params:        {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}\n",
      "\n",
      "Training params\n",
      "    Num Epochs: 5\n",
      "\n",
      "Display params\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save Training logs:        True\n",
      "    Save Intermediate models:  True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monk_v1/monk/system/imports.py:193: UserWarning: ArgumentWarning: clipnorm and clipvalue are active only for keras in current version of Monk\n",
      "  warnings.warn(msg)\n",
      "monk_v1/monk/system/imports.py:193: UserWarning: ArgumentWarning: momentum_dampening_rate is active only for pytorch in current version of Monk\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Compare-resnet-v1-depth\", \"resnet50-v1\");\n",
    "\n",
    "\n",
    "# Insert data and set params in default mode\n",
    "gtf.Default(dataset_path=\"blood-cells/train\", \n",
    "            model_name=\"resnet50_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "    Epoch 1/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4567f930b9fa4c778300af1222c1e0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b0bab3019a484997c2ee53390ffcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.01\n",
      "    [Epoch 1] Train-acc: 0.874, Train-loss: 0.326 | Val-acc: 0.955823, Val-loss: 0.126, | time: 109.1 sec\n",
      "\n",
      "    Epoch 2/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cab8e7c90e41acacbfc88f4efc48b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ad938e1db54042bb5545ca9231b7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.0098\n",
      "    [Epoch 2] Train-acc: 0.978, Train-loss: 0.077 | Val-acc: 0.989960, Val-loss: 0.032, | time: 108.9 sec\n",
      "\n",
      "    Epoch 3/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6c0deb7f5149ea9c016f52137b3c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e1f44ea6e14248a1dccdbb88e3b5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009604\n",
      "    [Epoch 3] Train-acc: 0.992, Train-loss: 0.024 | Val-acc: 0.945783, Val-loss: 0.153, | time: 107.8 sec\n",
      "\n",
      "    Epoch 4/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c9ab6f96ff4a4ca123618c9a35df37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2d3e6c05bf498aa43675a967847b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009411919999999999\n",
      "    [Epoch 4] Train-acc: 0.994, Train-loss: 0.021 | Val-acc: 0.988286, Val-loss: 0.030, | time: 108.1 sec\n",
      "\n",
      "    Epoch 5/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad56451762234162b0474154916a2d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18fd8a418d14f8397b58e829313baea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009223681599999999\n",
      "    [Epoch 5] Train-acc: 0.997, Train-loss: 0.010 | Val-acc: 0.997323, Val-loss: 0.008, | time: 107.8 sec\n",
      "\n",
      "    Training completed in: 8m 59s\n",
      "    Best val Acc:          0.997323\n",
      "\n",
      "Training End\n",
      "\n",
      "Training Outputs\n",
      "    Model Dir:   /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet50-v1/output/models/\n",
      "    Log Dir:     /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet50-v1/output/logs/\n",
      "    Final model: final\n",
      "    Best model:  best_model\n",
      "    Log 1 - Validation accuracy history log: val_acc_history.npy\n",
      "    Log 2 - Validation loss history log:     val_loss_history.npy\n",
      "    Log 3 - Training accuracy history log:   train_acc_history.npy\n",
      "    Log 4 - Training loss history log:       train_loss_history.npy\n",
      "    Log 5 - Training curve:                  train_loss_history.npy\n",
      "    Log 6 - Validation curve:                train_loss_history.npy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start Training\n",
    "gtf.Train();\n",
    "\n",
    "#Read the training summary generated once you run the cell and training is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.0\n",
      "\n",
      "Model Details\n",
      "    Loading model - workspace/Compare-resnet-v1-depth/resnet50-v1/output/models/final-symbol.json\n",
      "    Model loaded!\n",
      "\n",
      "Experiment Details\n",
      "    Project: Compare-resnet-v1-depth\n",
      "    Experiment: resnet50-v1\n",
      "    Dir: /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet50-v1/\n",
      "\n",
      "Dataset Details\n",
      "    Test path:      blood-cells/val\n",
      "    CSV test path:  None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:  224\n",
      "    Processors:   4\n",
      "\n",
      "Pre-Composed Test Transforms\n",
      "[{'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num test images: 2487\n",
      "    Num classes:      4\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc852f34e7bc42a39d74acb87f9369b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2487), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Result\n",
      "        class based accuracies\n",
      "            0. EOSINOPHIL - 85.87479935794543 %\n",
      "            1. LYMPHOCYTE - 100.0 %\n",
      "            2. MONOCYTE - 75.0 %\n",
      "            3. NEUTROPHIL - 92.94871794871796 %\n",
      "        total images:            2487\n",
      "        num correct predictions: 2200\n",
      "        Average accuracy (%):    88.45999195818254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load for validation\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Compare-resnet-v1-depth\", \"resnet50-v1\", eval_infer=True);\n",
    "\n",
    "\n",
    "# Set dataset\n",
    "gtf.Dataset_Params(dataset_path=\"blood-cells/val\");\n",
    "gtf.Dataset();\n",
    "\n",
    "\n",
    "# Validate\n",
    "accuracy, class_based_accuracy = gtf.Evaluate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# Train experiment with resnet-101 architecture and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.0\n",
      "\n",
      "Experiment Details\n",
      "    Project: Compare-resnet-v1-depth\n",
      "    Experiment: resnet101-v1\n",
      "    Dir: /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet101-v1/\n",
      "\n",
      "Dataset Details\n",
      "    Train path:     blood-cells/train\n",
      "    Val path:       None\n",
      "    CSV train path: None\n",
      "    CSV val path:   None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Data Shuffle: True\n",
      "    Processors:   4\n",
      "    Train-val split:   0.7\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 6969\n",
      "    Num val images:   2988\n",
      "    Num classes:      4\n",
      "\n",
      "Model Params\n",
      "    Model name:           resnet101_v1\n",
      "    Use Gpu:              True\n",
      "    Use pretrained:       True\n",
      "    Freeze base network:  False\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet101_v1\n",
      "        Num of potentially trainable layers:  209\n",
      "        Num of actual trainable layers:       209\n",
      "\n",
      "Optimizer\n",
      "    Name:          sgd\n",
      "    Learning rate: 0.01\n",
      "    Params:        {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Learning rate scheduler\n",
      "    Name:   steplr\n",
      "    Params: {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}\n",
      "\n",
      "Loss\n",
      "    Name:          softmaxcrossentropy\n",
      "    Params:        {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}\n",
      "\n",
      "Training params\n",
      "    Num Epochs: 5\n",
      "\n",
      "Display params\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save Training logs:        True\n",
      "    Save Intermediate models:  True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monk_v1/monk/system/imports.py:193: UserWarning: ArgumentWarning: clipnorm and clipvalue are active only for keras in current version of Monk\n",
      "  warnings.warn(msg)\n",
      "monk_v1/monk/system/imports.py:193: UserWarning: ArgumentWarning: momentum_dampening_rate is active only for pytorch in current version of Monk\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Compare-resnet-v1-depth\", \"resnet101-v1\");\n",
    "\n",
    "\n",
    "# Insert data and set params in default mode\n",
    "gtf.Default(dataset_path=\"blood-cells/train\", \n",
    "            model_name=\"resnet101_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "    Epoch 1/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4298d97d8284ff59a0c7ea5c04ae969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23f1caa07914c8db6ba430b434956b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.01\n",
      "    [Epoch 1] Train-acc: 0.823, Train-loss: 0.481 | Val-acc: 0.927376, Val-loss: 0.218, | time: 179.0 sec\n",
      "\n",
      "    Epoch 2/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948dfe3a91c447e4bdc3fd11a0d4c94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a7192762c2497db7b388a0cdcd6f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.0098\n",
      "    [Epoch 2] Train-acc: 0.950, Train-loss: 0.172 | Val-acc: 0.965863, Val-loss: 0.111, | time: 180.9 sec\n",
      "\n",
      "    Epoch 3/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1594ee658aef4c568785c1756e2d7809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e928288a6e74f47944737bee0a13a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009604\n",
      "    [Epoch 3] Train-acc: 0.976, Train-loss: 0.081 | Val-acc: 0.988621, Val-loss: 0.041, | time: 180.6 sec\n",
      "\n",
      "    Epoch 4/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f47412456a8463eb8b4c670ec8e79ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4be6e30026f46eb9e49a6c786fafa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009411919999999999\n",
      "    [Epoch 4] Train-acc: 0.984, Train-loss: 0.062 | Val-acc: 0.990964, Val-loss: 0.038, | time: 179.8 sec\n",
      "\n",
      "    Epoch 5/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d793057fcc490ba432382fd21ccd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0a32eea9e94d62857aa5e4967b9633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009223681599999999\n",
      "    [Epoch 5] Train-acc: 0.992, Train-loss: 0.034 | Val-acc: 0.991633, Val-loss: 0.035, | time: 178.5 sec\n",
      "\n",
      "    Training completed in: 14m 55s\n",
      "    Best val Acc:          0.991633\n",
      "\n",
      "Training End\n",
      "\n",
      "Training Outputs\n",
      "    Model Dir:   /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet101-v1/output/models/\n",
      "    Log Dir:     /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet101-v1/output/logs/\n",
      "    Final model: final\n",
      "    Best model:  best_model\n",
      "    Log 1 - Validation accuracy history log: val_acc_history.npy\n",
      "    Log 2 - Validation loss history log:     val_loss_history.npy\n",
      "    Log 3 - Training accuracy history log:   train_acc_history.npy\n",
      "    Log 4 - Training loss history log:       train_loss_history.npy\n",
      "    Log 5 - Training curve:                  train_loss_history.npy\n",
      "    Log 6 - Validation curve:                train_loss_history.npy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start Training\n",
    "gtf.Train();\n",
    "\n",
    "#Read the training summary generated once you run the cell and training is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.0\n",
      "\n",
      "Model Details\n",
      "    Loading model - workspace/Compare-resnet-v1-depth/resnet101-v1/output/models/final-symbol.json\n",
      "    Model loaded!\n",
      "\n",
      "Experiment Details\n",
      "    Project: Compare-resnet-v1-depth\n",
      "    Experiment: resnet101-v1\n",
      "    Dir: /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet101-v1/\n",
      "\n",
      "Dataset Details\n",
      "    Test path:      blood-cells/val\n",
      "    CSV test path:  None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:  224\n",
      "    Processors:   4\n",
      "\n",
      "Pre-Composed Test Transforms\n",
      "[{'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num test images: 2487\n",
      "    Num classes:      4\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14869fe801944a12b92839638bcdba2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2487), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Result\n",
      "        class based accuracies\n",
      "            0. EOSINOPHIL - 82.6645264847512 %\n",
      "            1. LYMPHOCYTE - 100.0 %\n",
      "            2. MONOCYTE - 75.16129032258064 %\n",
      "            3. NEUTROPHIL - 87.33974358974359 %\n",
      "        total images:            2487\n",
      "        num correct predictions: 2146\n",
      "        Average accuracy (%):    86.28870124648171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load for validation\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Compare-resnet-v1-depth\", \"resnet101-v1\", eval_infer=True);\n",
    "\n",
    "\n",
    "# Set dataset\n",
    "gtf.Dataset_Params(dataset_path=\"blood-cells/val\");\n",
    "gtf.Dataset();\n",
    "\n",
    "\n",
    "# Validate\n",
    "accuracy, class_based_accuracy = gtf.Evaluate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# Train experiment with resnet-152 architecture and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.0\n",
      "\n",
      "Experiment Details\n",
      "    Project: Compare-resnet-v1-depth\n",
      "    Experiment: resnet152-v1\n",
      "    Dir: /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet152-v1/\n",
      "\n",
      "Dataset Details\n",
      "    Train path:     blood-cells/train\n",
      "    Val path:       None\n",
      "    CSV train path: None\n",
      "    CSV val path:   None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Data Shuffle: True\n",
      "    Processors:   4\n",
      "    Train-val split:   0.7\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 6969\n",
      "    Num val images:   2988\n",
      "    Num classes:      4\n",
      "\n",
      "Model Params\n",
      "    Model name:           resnet152_v1\n",
      "    Use Gpu:              True\n",
      "    Use pretrained:       True\n",
      "    Freeze base network:  False\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet152_v1\n",
      "        Num of potentially trainable layers:  311\n",
      "        Num of actual trainable layers:       311\n",
      "\n",
      "Optimizer\n",
      "    Name:          sgd\n",
      "    Learning rate: 0.01\n",
      "    Params:        {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Learning rate scheduler\n",
      "    Name:   steplr\n",
      "    Params: {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}\n",
      "\n",
      "Loss\n",
      "    Name:          softmaxcrossentropy\n",
      "    Params:        {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}\n",
      "\n",
      "Training params\n",
      "    Num Epochs: 5\n",
      "\n",
      "Display params\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save Training logs:        True\n",
      "    Save Intermediate models:  True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monk_v1/monk/system/imports.py:193: UserWarning: ArgumentWarning: clipnorm and clipvalue are active only for keras in current version of Monk\n",
      "  warnings.warn(msg)\n",
      "monk_v1/monk/system/imports.py:193: UserWarning: ArgumentWarning: momentum_dampening_rate is active only for pytorch in current version of Monk\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Compare-resnet-v1-depth\", \"resnet152-v1\");\n",
    "\n",
    "\n",
    "# Insert data and set params in default mode\n",
    "gtf.Default(dataset_path=\"blood-cells/train\", \n",
    "            model_name=\"resnet152_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "    Epoch 1/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1bb86d3048b429e9cfc5899e70b4f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad1f3d3f71b4a1cac4a6ce096870f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.01\n",
      "    [Epoch 1] Train-acc: 0.893, Train-loss: 0.288 | Val-acc: 0.970549, Val-loss: 0.085, | time: 255.6 sec\n",
      "\n",
      "    Epoch 2/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c742c5dda54a669192325aba2d10cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f83e7eee5864a98a0709c3422c16637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.0098\n",
      "    [Epoch 2] Train-acc: 0.987, Train-loss: 0.041 | Val-acc: 0.990629, Val-loss: 0.028, | time: 259.6 sec\n",
      "\n",
      "    Epoch 3/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7580542a9c04684b90cb3d7fce5f236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7907e83b9464833b5da802f5024de3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009604\n",
      "    [Epoch 3] Train-acc: 0.992, Train-loss: 0.027 | Val-acc: 0.993307, Val-loss: 0.021, | time: 254.8 sec\n",
      "\n",
      "    Epoch 4/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e61dfbf54642a2b6a9d3dedc1f8b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3c13b95a5c4ba68b88874af7d3f018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009411919999999999\n",
      "    [Epoch 4] Train-acc: 0.998, Train-loss: 0.007 | Val-acc: 0.996653, Val-loss: 0.010, | time: 261.4 sec\n",
      "\n",
      "    Epoch 5/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cc029288674dea9126b36e3a6b09b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1743), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dd0fb08d684f88a861e05b53ab1abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.009223681599999999\n",
      "    [Epoch 5] Train-acc: 0.998, Train-loss: 0.007 | Val-acc: 0.997992, Val-loss: 0.007, | time: 261.3 sec\n",
      "\n",
      "    Training completed in: 21m 26s\n",
      "    Best val Acc:          0.997992\n",
      "\n",
      "Training End\n",
      "\n",
      "Training Outputs\n",
      "    Model Dir:   /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet152-v1/output/models/\n",
      "    Log Dir:     /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet152-v1/output/logs/\n",
      "    Final model: final\n",
      "    Best model:  best_model\n",
      "    Log 1 - Validation accuracy history log: val_acc_history.npy\n",
      "    Log 2 - Validation loss history log:     val_loss_history.npy\n",
      "    Log 3 - Training accuracy history log:   train_acc_history.npy\n",
      "    Log 4 - Training loss history log:       train_loss_history.npy\n",
      "    Log 5 - Training curve:                  train_loss_history.npy\n",
      "    Log 6 - Validation curve:                train_loss_history.npy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start Training\n",
    "gtf.Train();\n",
    "\n",
    "#Read the training summary generated once you run the cell and training is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.0\n",
      "\n",
      "Model Details\n",
      "    Loading model - workspace/Compare-resnet-v1-depth/resnet152-v1/output/models/final-symbol.json\n",
      "    Model loaded!\n",
      "\n",
      "Experiment Details\n",
      "    Project: Compare-resnet-v1-depth\n",
      "    Experiment: resnet152-v1\n",
      "    Dir: /home/abhi/Desktop/Work/tess_tool/gui/v0.3/finetune_models/Organization/development/v5.0_blocks/study_roadmap/change_post_num_layers/6_transfer_learning_model_params/1_exploring_model_families/3_resnet/workspace/Compare-resnet-v1-depth/resnet152-v1/\n",
      "\n",
      "Dataset Details\n",
      "    Test path:      blood-cells/val\n",
      "    CSV test path:  None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:  224\n",
      "    Processors:   4\n",
      "\n",
      "Pre-Composed Test Transforms\n",
      "[{'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num test images: 2487\n",
      "    Num classes:      4\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0142717df44998ad20964081ade25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2487), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Result\n",
      "        class based accuracies\n",
      "            0. EOSINOPHIL - 79.61476725521669 %\n",
      "            1. LYMPHOCYTE - 97.90322580645162 %\n",
      "            2. MONOCYTE - 75.0 %\n",
      "            3. NEUTROPHIL - 90.7051282051282 %\n",
      "        total images:            2487\n",
      "        num correct predictions: 2134\n",
      "        Average accuracy (%):    85.80619219943706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load for validation\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Compare-resnet-v1-depth\", \"resnet152-v1\", eval_infer=True);\n",
    "\n",
    "\n",
    "# Set dataset\n",
    "gtf.Dataset_Params(dataset_path=\"blood-cells/val\");\n",
    "gtf.Dataset();\n",
    "\n",
    "\n",
    "# Validate\n",
    "accuracy, class_based_accuracy = gtf.Evaluate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11'></a>\n",
    "# Comparing all the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the comparison class\n",
    "from compare_prototype import compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and managing comparison experiments\n",
    "        - Provide project name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: - Compare-effect-of-network-depth\n"
     ]
    }
   ],
   "source": [
    "# Create a project \n",
    "gtf = compare(verbose=1);\n",
    "gtf.Comparison(\"Compare-effect-of-network-depth\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This creates files and directories as per the following structure\n",
    "    \n",
    "    workspace\n",
    "        |\n",
    "        |--------comparison\n",
    "                        |\n",
    "                        |\n",
    "                        |-----Compare-effect-of-network-depth\n",
    "                                    |\n",
    "                                    |------stats_best_val_acc.png\n",
    "                                    |------stats_max_gpu_usage.png\n",
    "                                    |------stats_training_time.png\n",
    "                                    |------train_accuracy.png\n",
    "                                    |------train_loss.png\n",
    "                                    |------val_accuracy.png\n",
    "                                    |------val_loss.png\n",
    "                                    \n",
    "                        |\n",
    "                        |-----comparison.csv (Contains necessary details of all experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the experiments\n",
    "        - First argument - Project name\n",
    "        - Second argument - Experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project - Compare-resnet-v1-depth, Experiment - resnet18-v1 added\n",
      "Project - Compare-resnet-v1-depth, Experiment - resnet34-v1 added\n",
      "Project - Compare-resnet-v1-depth, Experiment - resnet50-v1 added\n",
      "Project - Compare-resnet-v1-depth, Experiment - resnet101-v1 added\n",
      "Project - Compare-resnet-v1-depth, Experiment - resnet152-v1 added\n"
     ]
    }
   ],
   "source": [
    "gtf.Add_Experiment(\"Compare-resnet-v1-depth\", \"resnet18-v1\");\n",
    "gtf.Add_Experiment(\"Compare-resnet-v1-depth\", \"resnet34-v1\");\n",
    "gtf.Add_Experiment(\"Compare-resnet-v1-depth\", \"resnet50-v1\");\n",
    "gtf.Add_Experiment(\"Compare-resnet-v1-depth\", \"resnet101-v1\");\n",
    "gtf.Add_Experiment(\"Compare-resnet-v1-depth\", \"resnet152-v1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating statistics...\n",
      "Generated\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gtf.Generate_Statistics();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and study comparison metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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
